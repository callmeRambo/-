{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工神经网络之感知器算法\n",
    "https://www.cnblogs.com/liuwu265/p/4694729.html\n",
    "感知器算法的主要流程：\n",
    "\n",
    "　　首先得到n个输入，再将每个输入值加权，然后判断感知器输入的加权和最否达到某一阀值v，若达到，则通过sign函数输出1，否则输出-1。\n",
    "1、训练集线性可分时 --> 感知器训练法则\n",
    "\n",
    "2、训练集线性不可分时 --> delta法则\n",
    "根据loss函数利用梯度递降\n",
    "\n",
    "二个区别：\n",
    "\n",
    "1）感知器训练法则 和 delta法则（增量法则）\n",
    "\n",
    "　　关键区别在于：感知器训练法则根据阀值化的感知器输出的误差更新权值；而增量法则根据输入的非阀值化线性组合的误差来更新权值。\n",
    "\n",
    "　　二者的权值更新公式看似一样，实则不同：感知器法则的o是指阀值的输出：，而增量法则中的o是线性单元的输出：\n",
    "\n",
    "2）（标准）梯度下降 和 随机梯度下降\n",
    "\n",
    "　　梯度下降每轮遍历所有训练样例，将每个样例得到权向量的差值进行累加，最终将这些差值之和累加到初始的权向量上；而随机梯度下降则是在每个训练样例中都会更新权重，最终得到一个损失函数较小的权向量。\n",
    "\n",
    " \n",
    "\n",
    "3、梯度下降法则的推导\n",
    "\n",
    "梯度下降算法的核心就是每次向损失函数下降最陡峭的方向移动，而最陡峭的方向通常就是损失函数对权向量求偏导数得到的向量的反方向。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
